<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jishen Yin</title>
    <link>https://yinjishen.github.io/</link>
    <description>Recent content on Jishen Yin</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 24 Dec 2020 14:38:17 -0500</lastBuildDate>
    
	<atom:link href="https://yinjishen.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>第五章：PyTorch实现线性回归</title>
      <link>https://yinjishen.github.io/pytorch/v/</link>
      <pubDate>Thu, 24 Dec 2020 14:38:17 -0500</pubDate>
      
      <guid>https://yinjishen.github.io/pytorch/v/</guid>
      <description>此为深度学习书籍《Deep Learning with Pytorch》学习笔记整理系列第四期，因为电脑配置问题，将跳过涉及CUDA/GPU的内容
书籍pdf链接：https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf
书籍附源代码链接：https://github.com/deep-learning-with-pytorch/dlwpt-code
注：所有实现代码均包含以下命令，此后将省略
%matplotlib inline import matplotlib.pyplot as plt #导入可视化库matplotlib.pyplot import numpy as np #导入tensor常规处理库 #Pytorch主要部件导入 import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim torch.set_printoptions(edgeitems=2) #输出长tensor时，保留首尾各2个元素 torch.manual_seed(123) #设置随机数种子 第五章：线性回归的从零实现 5.1 PyTorch自动求梯度原理 PyTorch的核心功能就在于自动求梯度。我们知道，深度学习的过程实际上就是不断地调整模型里的参数，使得损失函数尽可能的小。那么我们就会迫切地关注损失函数关于代求参数的梯度，用于更新参数。在PyTorch定义待估参数的tensor时，可以加入选项requires_grad=True以提供存储梯度的空间。当我们使用参数计算出损失函数值loss时，便可以调用loss.backward()，以回溯至所有和loss相关的带梯度tensor，此时所有requires_grad=True的参数所附的梯度值会自动更新。
这里需要注意的是，如果重复backward，梯度值是叠加而不是覆盖，所以在循环的时候，要仔细检查是否需要不停地将梯度清零，即params.grad.zero_()（带下划线表示内部操作）。
5.2 实现线性回归 数据 t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0] t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.</description>
    </item>
    
    <item>
      <title>第四章：将实际数据转换成tensor</title>
      <link>https://yinjishen.github.io/pytorch/iv/</link>
      <pubDate>Wed, 23 Dec 2020 15:29:59 -0500</pubDate>
      
      <guid>https://yinjishen.github.io/pytorch/iv/</guid>
      <description>此为深度学习书籍《Deep Learning with Pytorch》学习笔记整理系列第四期，因为电脑配置问题，将跳过涉及CUDA/GPU的内容
书籍pdf链接：https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf
书籍附源代码链接：https://github.com/deep-learning-with-pytorch/dlwpt-code
注：所有实现代码均包含以下命令，此后将省略
%matplotlib inline import matplotlib.pyplot as plt #导入可视化库matplotlib.pyplot import numpy as np #导入tensor常规处理库 #Pytorch主要部件导入 import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim torch.set_printoptions(edgeitems=2) #输出长tensor时，保留首尾各2个元素 torch.manual_seed(123) #设置随机数种子 第四章：将实际数据转化为Tensor 4.1 2D图像 2D图像以网格形式进行储存，每一个网格被视作一个像素点pixel，存储一个或多个标量值。因此，2D图形是一个至少二维的tensor，包括图形的宽和高。有的图形不包括第三维度，这种图形被称为灰度图，每个像素点的值代表灰度，从0到1的连续值，从白到黑。有的图形包括第三维度，例如RGB，第三维度对应红绿蓝三个频道。
为了加载单个2D图形文件，我们可使用库imageio进行加载。如下图所示，该图片分辨率为720*1280，且为RGB图形。
import imageio img_arr = imageio.imread(&#39;../data.p1ch4/image_dog/bobby.jpg&#39;) #地址 img_arr.shape # 输出(720, 1280, 3) 这样我们得到一个array类的变量，下面将其进行转化，并使用permute将频道维度提到首位
img = torch.from_numpy(img_arr) out = img.permute(2, 0, 1) #指变换后的维度为(shape[2], shape[0], shape[1])=(3, 720, 1280) 下面我们给出读取多个文件的模板，可视情况进行变化，核心函数为os.listdir和os.path.join
import os data_dir = &#39;.</description>
    </item>
    
    <item>
      <title>第三章：PyTorch中的tensor相关操作总结</title>
      <link>https://yinjishen.github.io/pytorch/iii/</link>
      <pubDate>Mon, 21 Dec 2020 23:00:05 -0500</pubDate>
      
      <guid>https://yinjishen.github.io/pytorch/iii/</guid>
      <description>此为深度学习书籍《Deep Learning with Pytorch》学习笔记整理系列第三期，因为电脑配置问题，将跳过涉及CUDA/GPU的内容
书籍pdf链接：https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf
书籍附源代码链接：https://github.com/deep-learning-with-pytorch/dlwpt-code
注：所有实现代码均包含以下命令，此后将省略
%matplotlib inline import matplotlib.pyplot as plt #导入可视化库matplotlib.pyplot import numpy as np #导入tensor常规处理库 #Pytorch主要部件导入 import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim torch.set_printoptions(edgeitems=2) #输出长tensor时，保留首尾各2个元素 torch.manual_seed(123) #设置随机数种子 第三章：Tensor 3.1 浮点数的世界 PyTorch处理数据的主要渠道是浮点数，无论是何种形式的数据（图片、文字、语音等等），都需要通过适当的模型转化成浮点数数据，才能有效地输入网络进行训练。
PyTorch引入了数据结构张量（tensor）来存储并处理浮点数数据。张量，通俗地讲，就是多维向量。多维向量的维度代表从整体索引到具体的标量元素所需要的下标数量。
3.2 PyTorch关于tensor的基本操作 构造 如何创建一个tensor？三种方式
 将其它形式的数据转化成torch.Tensor，例如torch.from_numpy()、torch.tensot()等 构造指定维度的零向量或一向量，例如zeros、ones等 生成随机向量，例如randn、normal等  索引、切片、变换等 注：索引一律”左闭右开“，即包含起点，不包含终点
一维索引：
points[1:4]指从1号元素到4号元素（不包含4号元素）
points[1:]指从1号元素到末尾
points[:-1]指从头到倒数第一位元素（不包含倒数第一位元素）
二维索引：
points[1:, :]指从1号行到末尾，所有列的元素
points[1:, :]指从1号行到末尾，0号列的元素
变形：
points.transpose()：转置
points.t()：无复制转置（变量存储地址不变）
数学操作（加下划线_可能变为内部操作，即in-place） 逐点运算：cos、abs等
降维运算：mean、std、norm等
比较运算：equal、max等</description>
    </item>
    
    <item>
      <title>第二章：预训练模型（偏趣味）</title>
      <link>https://yinjishen.github.io/pytorch/ii/</link>
      <pubDate>Mon, 14 Dec 2020 17:16:51 -0500</pubDate>
      
      <guid>https://yinjishen.github.io/pytorch/ii/</guid>
      <description>此为深度学习书籍《Deep Learning with Pytorch》学习笔记整理系列第二期，因为电脑配置问题，将跳过涉及CUDA/GPU的内容
书籍pdf链接：https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf
书籍附源代码链接：https://github.com/deep-learning-with-pytorch/dlwpt-code
注：所有实现代码均包含以下命令，此后将省略
%matplotlib inline import matplotlib.pyplot as plt #导入可视化库matplotlib.pyplot import numpy as np #导入tensor常规处理库 #Pytorch主要部件导入 import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim torch.set_printoptions(edgeitems=2) #输出长tensor时，保留首尾各2个元素 torch.manual_seed(123) #设置随机数种子 第二章：预训练模型 这章主要介绍了torchvision.models中的一些预训练模型，预训练模型是指：
 模型结构确定，无需自己建立模型 模型中的大量系数已被训练好，可以直接下载，无需重新训练  在实际应用中，很少遇到可以直接使用预训练模型的情况，所以这一章更多以好玩为主。这章主要介绍了三个案例
 给图片加标签 对图片进行主题转换 为图片提供描述文字  问题本身可推广性并不强，所以这篇学习笔记主要侧重于对模型原理的介绍，以及代码中涉及到的PyTorch函数说明。
2.1 给图片加标签 图像分类是经典的多分类问题。在训练集中，我们拥有大量拥有标签（如：鸟、老虎、红绿灯等）的图片，我们希望对训练集建立网络，通过训练得到一个自动标注系统，可以对任意新图片进行标注。数据集是著名的ImageNet数据集（http://imagenet.stanford.edu），该数据集包含超过一千四百万张带标注的图片，因此有很多相关联的算法赛。其中，ILSVRC是颇受欢迎的一个竞赛。该竞赛每年会针对ImageNet数据集提出很多问题供大家比赛使用。比如说，图像分类任务就是给你一些图片，要求对每个图片输出5个标签（所有标签共有1000种），竞赛的检验标准是top-5误差率，也就是实际标签不在这五个结果里的比例。以上是此书2.1的问题描述。
在陈述模型之前，先陈述数据预处理方法。此问题的数据，都是png格式的图片。因为是RGB格式，所以每张图片实际上是3*w*h，3表示红绿蓝三个颜色，w和h是图片宽高，所有元素值都是0-255的整数。因为不同图片的大小很可能不同，因此我们需要将其进行统一，即压缩至同一个大小。torchvision.transforms中有大量的图像预处理函数，详情见https://pytorch.org/docs/stable/torchvision/transforms.html。这里我们先给出此问题预处理代码
from torchvision import transforms preprocess = transforms.Compose([ transforms.Resize(256), #缩放 transforms.CenterCrop(224), #剪裁 transforms.ToTensor(), #PILImage格式变成tensor格式 transforms.Normalize( #标准化 mean=[0.</description>
    </item>
    
    <item>
      <title>引言及第一章：深度学习与Pytorch的安装和配置</title>
      <link>https://yinjishen.github.io/pytorch/i/</link>
      <pubDate>Sun, 13 Dec 2020 16:36:06 -0500</pubDate>
      
      <guid>https://yinjishen.github.io/pytorch/i/</guid>
      <description>此为深度学习书籍《Deep Learning with Pytorch》学习笔记整理系列第一期，因为电脑配置问题，将跳过涉及CUDA/GPU的内容
书籍pdf链接：https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf
书籍附源代码链接：https://github.com/deep-learning-with-pytorch/dlwpt-code
注：所有实现代码均包含以下命令，此后将省略
%matplotlib inline import matplotlib.pyplot as plt #导入可视化库matplotlib.pyplot import numpy as np #导入tensor常规处理库 #Pytorch主要部件导入 import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim torch.set_printoptions(edgeitems=2) #输出长tensor时，保留首尾各2个元素 torch.manual_seed(123) #设置随机数种子 结构框架 本书共分为三部分
第一部分：1-8章 理解Pytorch所需的基本知识，以及如何建立自己的Pytorch项目。
第二部分：9-14章 肺癌检测系统的建立，各章将逐步递进，以理解深度学习项目在实际操作中的技巧与注意事项。
第三部分：15章 如何将Pytorch模型部署在网络服务平台，嵌入C++项目，或植入手机系统
第一章：深度学习简介与Pytorch库 1.1 深度学习革命 二十年前，多数涉及机器学习的方法都以特征工程为核心。特征是指经过变换的输入数据，用于帮助算法（如分类、回归、聚类）的实现。而变换方法既取决于实际问题，更依赖于先验知识。例如，在手写数字识别问题中，为了区分0和1两种数字，我们需要完成一系列的过滤器来估计图形边的方向（此步骤为特征工程），并根据这些方向的分布建立分类器进行学习。当然，我们也可以使用“闭环的数量”这一特征，来区分0、8、22等。
而深度学习，致力于自动完成特征工程，以用于分类。也就是说，以区分0和1为例，深度学习模型会在训练过程中自动寻找有用的特征，并不断更新。当然，这仍然需要我们对相关问题的背景有充足的先验知识，但深度学习模型的关键点在于，它不注重于具体特征的构造与实现，而更加关注如何利用数学知识使其能够自动完成特征的寻找与更正。
如下图所示，左图是一个深度学习工程师，她只需要将原数据直接扔进黑箱子，在黑箱子内部自动完成清洗、整理、预测等一系列工作。而右图是一个传统的机器学习工程师，在进行模型训练之前，他需要将数据先进行手动处理，再扔进机器例进行运转。两者的区别在于，左图中的系统发现结果不令人满意，会自动调整数据的处理方式。而右图中的系统再产生不理想的结果后，工程师仍需要手动调整，直至得到满意的结果。
1.2 Pytorch安装与配置 Pytorch是专门用于深度学习的非常强大的库，如下图所示，Pytorch可以实现一个大型深度学习项目的完整链条。首先，我们需要把原数据转化为Pytorch的核心组件——tensor。随后对模型进行训练，此过程可与分布式计算系统进行交互。训练完成后，可将训练结果按照实际需求进行部署。
 同样，Pytorch的安装非常简单。它为我们提供了非常完善的文档来帮助我们安装，我们只需要上Pytorch官网（https://pytorch.org/get-started/locally/），针对自己的需求选择版本与操作系统，即可自动生成安装命令。
如果是在anaconda下的环境运行python，则打开anaconda prompt粘贴对应命令。如果是在本地环境下运行python，则打开cmd命令行窗口（windows）/terminal（mac）粘贴对应命令。</description>
    </item>
    
    <item>
      <title>COVID-19 Team Project</title>
      <link>https://yinjishen.github.io/bio/fp823/</link>
      <pubDate>Sun, 15 Nov 2020 19:15:13 -0500</pubDate>
      
      <guid>https://yinjishen.github.io/bio/fp823/</guid>
      <description>This is the final project of BIOSTAT823: Statistical Programming for Big Data in 2020 Fall Semester at Duke. Our team name is &amp;ldquo;Durham Sloths&amp;rdquo;. This project is finished by Zhuoran Hou(https://github.com/ZhuoranHou), Qianyin Lu (https://github.com/QianyinLu), Jishen Yin (https://github.com/YinJishen) and Zewen Zhang (https://github.com/zewenzhang1007).
Project GitHub Page: https://github.com/YinJishen/BIOSTAT823-Final-Project
In this project, we mainly work on the analysis on different aspects of COVID-19 data. In part 1, we recreated the overview of COVID-19 in U.</description>
    </item>
    
    <item>
      <title>Deep learning model fitting for insect classification</title>
      <link>https://yinjishen.github.io/bio/deeplearning/</link>
      <pubDate>Thu, 05 Nov 2020 16:57:40 -0500</pubDate>
      
      <guid>https://yinjishen.github.io/bio/deeplearning/</guid>
      <description>GitHub Page: https://github.com/YinJishen/Biostat823-Homework/tree/master/hw7
Data Source: https://www.insectimages.org/index.cfm
LeNet Model In this homework, I used the simplest CNN model &amp;mdash;&amp;mdash; LeNet[1] to train the data with pytorch(version: 1.5.1+cpu+windows). The structure of the network is shown below
Result Training and test accuracy is shown below
Reference [1] LeCun, Y., Bottou, L., Bengio, Y., &amp;amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.</description>
    </item>
    
    <item>
      <title>Dashboard for Data of PhDs Awarded in the US</title>
      <link>https://yinjishen.github.io/bio/dashboard/</link>
      <pubDate>Wed, 04 Nov 2020 20:07:49 -0500</pubDate>
      
      <guid>https://yinjishen.github.io/bio/dashboard/</guid>
      <description>Data Source: https://ncses.nsf.gov/pubs/nsf19301/data
GitHub Page: https://github.com/YinJishen/Biostat823-Homework/tree/master/hw6
Dashboard Url: https://demo-case.herokuapp.com/
In this homework, I used two table: table 4 and table 6. The preprocess steps are in preprocess.ipynb file. I mainly used melt and concat function in pandas to change the data from the wide format into long format. For data in table 6, there are some &amp;ldquo;D&amp;rdquo; numbers that indicate confidential data, I cleared this data before doing the visualization part in case that the error message arises.</description>
    </item>
    
    <item>
      <title>Oldest Character in Star Wars Series</title>
      <link>https://yinjishen.github.io/bio/star_war/</link>
      <pubDate>Fri, 23 Oct 2020 15:31:49 -0400</pubDate>
      
      <guid>https://yinjishen.github.io/bio/star_war/</guid>
      <description>Source Code: https://github.com/YinJishen/Biostat823-Homework/tree/master/hw5
API documentation: https://swapi.dev/documentation
Download the data This problem requires us to find all people and all films using the API. Since the url is formatted such as &amp;ldquo;https://swapi.dev/api/people/32&amp;quot; or &amp;ldquo;https://swapi.dev/api/films/3&amp;quot;.
So in order to get all people and films, I looped from 1 to 100 for &amp;ldquo;people&amp;rdquo; and 1 to 10 for &amp;ldquo;film&amp;rdquo;. If the url does not work, it will return {&amp;ldquo;details&amp;rdquo;: None}. So I can filter this result by checking if &amp;ldquo;details&amp;rdquo; is in the json file.</description>
    </item>
    
    <item>
      <title>Third Normal Form of Spotify Song Dataset</title>
      <link>https://yinjishen.github.io/bio/3nf/</link>
      <pubDate>Thu, 08 Oct 2020 14:46:55 -0400</pubDate>
      
      <guid>https://yinjishen.github.io/bio/3nf/</guid>
      <description>Data source: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md
Source Code: https://github.com/YinJishen/Biostat823-Homework/tree/master/hw4
1NF To get the first normal form. I firstly checked the uniqueness of rows and columns. There is no duplicate for both dimensions. And all cells only contain one elements. So I simply make some data cleaning work. For duration_ms, I translated it into duration_min by dividing 60,000. And for track_name and track_album_name, I noticed that there are a lot of &amp;ldquo;remix&amp;rdquo; and &amp;ldquo;feat&amp;rdquo; words in the name, which I believe is unnecessary.</description>
    </item>
    
    <item>
      <title>Visualization</title>
      <link>https://yinjishen.github.io/bio/visualization/</link>
      <pubDate>Tue, 22 Sep 2020 16:31:21 -0400</pubDate>
      
      <guid>https://yinjishen.github.io/bio/visualization/</guid>
      <description>The detailed code is on GitHub. https://github.com/YinJishen/Biostat823-Homework/tree/master/hw3
In the first graph, I chose the top 5 countries which have the largest average death rate in the past 20 years. (Sierra Leone, Burkina Faso, Uganda, Equatorial Guinea and Cote d&amp;rsquo;lvoire)
From this graph, we can see that there are two different trends. For Uganda (Green line), the death rate keeps decreasing. And for the other four countries, the death rate increases in the first 10 years and then decreases.</description>
    </item>
    
    <item>
      <title>Euler Project</title>
      <link>https://yinjishen.github.io/bio/euler-project/</link>
      <pubDate>Tue, 01 Sep 2020 18:58:20 -0400</pubDate>
      
      <guid>https://yinjishen.github.io/bio/euler-project/</guid>
      <description>All detailed solutions and codes are stored in https://github.com/YinJishen/Biostat823-Homework/tree/master/hw2
Problem 8 (Accepted: 351189) https://projecteuler.net/problem=8
The four adjacent digits in the 1000-digit number that have the greatest product are 9 × 9 × 8 × 9 = 5832.
73167176531330624919225119674426574742355349194934 96983520312774506326239578318016984801869478851843 85861560789112949495459501737958331952853208805511 12540698747158523863050715693290963295227443043557 66896648950445244523161731856403098711121722383113 62229893423380308135336276614282806444486645238749 30358907296290491560440772390713810515859307960866 70172427121883998797908792274921901699720888093776 65727333001053367881220235421809751254540594752243 52584907711670556013604839586446706324415722155397 53697817977846174064955149290862569321978468622482 83972241375657056057490261407972968652414535100474 82166370484403199890008895243450658541227588666881 16427171479924442928230863465674813919123162824586 17866458359124566529476545682848912883142607690042 24219022671055626321111109370544217506941658960408 07198403850962455444362981230987879927244284909188 84580156166097919133875499200524063689912560717606 05886116467109405077541002256983155200055935729725 71636269561882670428252483600823257530420752963450 Find the thirteen adjacent digits in the 1000-digit number that have the greatest product.</description>
    </item>
    
    <item>
      <title>Building a GitHub Page with theme using Hugo (Windows)</title>
      <link>https://yinjishen.github.io/bio/github-pages/</link>
      <pubDate>Wed, 26 Aug 2020 20:09:25 -0400</pubDate>
      
      <guid>https://yinjishen.github.io/bio/github-pages/</guid>
      <description>This is my first personal blog built with Hugo, and it took me a really long time to read the official guideline and work through every single details.
Preparation Since my computer&amp;rsquo;s system is Windows 10, which makes it less convenient to finish this job, I need to do the following preparations before all steps.
  Install Chocolatey to install Hugo
  Install Hugo with Chocolatey
  Install Typora (Markdown editor)</description>
    </item>
    
  </channel>
</rss>