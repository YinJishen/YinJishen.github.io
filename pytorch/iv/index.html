<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>第四章：将实际数据转换成tensor - Jishen Yin</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta itemprop="name" content="第四章：将实际数据转换成tensor">
<meta itemprop="description" content="包含2D图形、3D图形、表格数据、时间序列、文本数据的基本处理方式">
<meta itemprop="datePublished" content="2020-12-23T15:29:59-05:00" />
<meta itemprop="dateModified" content="2020-12-23T15:29:59-05:00" />
<meta itemprop="wordCount" content="132">



<meta itemprop="keywords" content="" />
<meta property="og:title" content="第四章：将实际数据转换成tensor" />
<meta property="og:description" content="包含2D图形、3D图形、表格数据、时间序列、文本数据的基本处理方式" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yinjishen.github.io/pytorch/iv/" />
<meta property="article:published_time" content="2020-12-23T15:29:59-05:00" />
<meta property="article:modified_time" content="2020-12-23T15:29:59-05:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="第四章：将实际数据转换成tensor"/>
<meta name="twitter:description" content="包含2D图形、3D图形、表格数据、时间序列、文本数据的基本处理方式"/>
<link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" media="screen" href="https://yinjishen.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://yinjishen.github.io/css/main.css" />

        <link id="dark-scheme" rel="stylesheet" type="text/css" href="https://yinjishen.github.io/css/dark.css" />

	<script src="https://yinjishen.github.io/js/feather.min.js"></script>
	
		<script src="https://yinjishen.github.io/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	
	<h1 class="site-title"><a href="https://yinjishen.github.io/">Jishen Yin</a></h1>
	<div class="site-description"><nav class="nav social">
			<ul class="flat"><li><a href="https://github.com/YinJishen" title="Github"><i data-feather="github"></i></a></li></ul>
		</nav></div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/bio">Biostat 823</a>
			</li>
			
			<li>
				<a href="/pytorch">Pytorch</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post">
			<div class="post-header">
				
					<div class="meta">
						<div class="date">
							<span class="day">23</span>
							<span class="rest">Dec 2020</span>
						</div>
					</div>
				
				<div class="matter">
					<h1 class="title">第四章：将实际数据转换成tensor</h1>
				</div>
			</div>
					
			<div class="markdown">
				<p>此为深度学习书籍《Deep Learning with Pytorch》学习笔记整理系列第四期，因为电脑配置问题，将跳过涉及CUDA/GPU的内容</p>
<p>书籍pdf链接：https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf</p>
<p>书籍附源代码链接：https://github.com/deep-learning-with-pytorch/dlwpt-code</p>
<p>注：所有实现代码均包含以下命令，此后将省略</p>
<pre><code>%matplotlib inline
import matplotlib.pyplot as plt #导入可视化库matplotlib.pyplot
import numpy as np #导入tensor常规处理库

#Pytorch主要部件导入
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

torch.set_printoptions(edgeitems=2) #输出长tensor时，保留首尾各2个元素
torch.manual_seed(123) #设置随机数种子
</code></pre><h1 id="第四章将实际数据转化为tensor">第四章：将实际数据转化为Tensor</h1>
<h2 id="41-2d图像">4.1 2D图像</h2>
<p>2D图像以网格形式进行储存，每一个网格被视作一个<strong>像素点pixel</strong>，存储一个或多个标量值。因此，2D图形是一个至少二维的tensor，包括图形的宽和高。有的图形不包括第三维度，这种图形被称为灰度图，每个像素点的值代表灰度，从0到1的连续值，从白到黑。有的图形包括第三维度，例如<strong>RGB</strong>，第三维度对应红绿蓝三个<strong>频道</strong>。</p>
<p>为了加载单个2D图形文件，我们可使用库<code>imageio</code>进行加载。如下图所示，该图片分辨率为720*1280，且为RGB图形。</p>
<pre><code>import imageio

img_arr = imageio.imread('../data.p1ch4/image_dog/bobby.jpg') #地址
img_arr.shape  # 输出(720, 1280, 3)
</code></pre><p>这样我们得到一个array类的变量，下面将其进行转化，并使用<code>permute</code>将频道维度提到首位</p>
<pre><code>img = torch.from_numpy(img_arr)
out = img.permute(2, 0, 1) #指变换后的维度为(shape[2], shape[0], shape[1])=(3, 720, 1280)
</code></pre><p>下面我们给出读取多个文件的模板，可视情况进行变化，核心函数为<code>os.listdir</code>和<code>os.path.join</code></p>
<pre><code>import os

data_dir = '../data/p1ch4/image-cats/' # 要遍历的目录
filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png'] # 提取目录下的所有文件，if后的部分视情况加，此处指只提取.png结尾
for i, filename in enumerate(filenames):
	img_arr = imageio.imread(os.path.join（data_dir, filename)
	pass ## 后续操作
</code></pre><h2 id="42-3d图像">4.2 3D图像</h2>
<p>3D图像在医疗领域用得比较多，简答介绍一下，使用<code>imageio.volread</code>可以读取，其余类似，不再赘述</p>
<h2 id="43-表格数据">4.3 表格数据</h2>
<p>这种是最常见的核心类型，我们拿到一个n*p的表格，其中有一列是我们需要预测的，剩下的作为自变量。那么我们就可以通过<code>numpy</code>、<code>pandas</code>等库将表格读取（比如<code>pd.read_csv</code>、<code>np.loadtxt</code>、<code>csv.reader</code>等）后分离成<code>data</code>和<code>target</code>两部分。对于<strong>离散</strong>的数据类型，我们可以通过<strong>one-hot</strong>将其转化，例如：包括五种颜色的离散数据，转化成one-hot之后，第1种颜色就变成了[1, 0, 0, 0, 0]。这样做的意义在于，12345作为数字是存在大小关系的，而且可以加减乘除，但五种颜色作为离散变量，应该是相互独立的关系，而且不应有大小比较关系。因此将其扩成一个五维向量，这样不同维度之间的独立关系满足实际的需要。</p>
<pre><code>#onehot模板
target_onehot = torch.zeros(target.shape[0], 10)
target_onehot.scatter_(1, target.unsqueeze(1), 1.0)
</code></pre><p>但是，有一种特殊的离散数据叫做<strong>层次数据</strong>，我们在填各种调查问卷的时候经常遇到，形如“非常满意”、“比较满意”、“不满意”、“非常不满意”类的选项。这种虽然是离散型，但彼此间有明显的层序关系，这样的数据处理起来要谨慎，视情况而定。</p>
<p><img src="/pytorch/4/4-1.PNG" alt="image"></p>
<!-- raw HTML omitted -->
<h2 id="44-时间序列数据">4.4 时间序列数据</h2>
<p>这部分没什么通用的方法，时间序列的核心特征是<strong>周期性</strong>，比如天气按季节周期性变换、温度按小时周期性变换等等。所以当我们拿到一串时间序列数据，很可能会希望将其内部的周期提取出来，比如一个包含一年的气温数据的时间序列，一小时为单位。我们可能会希望将其转化成24*n的形状，来将同一小时的气温数据置于一列便于分析。PyTorch中的<code>view</code>可以非常便利的实现这一功能，详情见https://pytorch.org/docs/stable/tensor_view.html</p>
<h2 id="45-文本数据">4.5 文本数据</h2>
<p>如何将文本转化为tensor，这甚至是一个机器学习的核心分支——<strong>自然语言处理</strong>的核心部分。几十年来，通过网络训练将文本数据向量化的模型层出不穷。这里我们只介绍最基本的方式——one-hot。也就是说，如果单词库中有1,000,000个词汇，那么每一个词汇都是一个1,000,000维的向量，其中词汇的编号所在的位置为1，其余为0。这种方式非常直观，编程非常便利，但基本毫无实际价值，因此它存在几大致命缺点：</p>
<ol>
<li>向量是稀疏的，高维空间中的稀疏向量处理起来很麻烦，这也是很多推荐系统算法被开发出来的原因</li>
<li>用0-1向量，代表着不同单词的地位相同，而且词与词之间两两独立（内积为0），这显然不符合像语义识别这样的实际需求</li>
<li>词库是不停更新的，随着时代的变迁，会有很多新鲜词汇不断加入，这意味着，向量的维度也在不断变化，也就是网络的输入空间都发生了变化。这会导致统计学中经常提及的curse of dimensionity。</li>
</ol>
<p>因此，实际开发出的文本数据向量化的方法，几乎都是基于<strong>稠密低维向量</strong>，也就是我们经常说的<strong>嵌入embedding</strong>。基本的方法有GloVec、skip-gram等，高级的有transformer、BERT等。</p>
<p><img src="/pytorch/4/4-2.PNG" alt="image"></p>
<!-- raw HTML omitted -->

			</div>

			<div class="tags">
				
					
				
			</div></div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div>2020  <a href="https://github.com/knadh/hugo-ink">Ink</a> theme on <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>

<script>feather.replace()</script>
</body>
</html>
