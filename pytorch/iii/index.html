<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>第三章：PyTorch中的tensor相关操作总结 - Jishen Yin</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta itemprop="name" content="第三章：PyTorch中的tensor相关操作总结">
<meta itemprop="description" content="PyTorch的核心数据类型tensor的相关操作">
<meta itemprop="datePublished" content="2020-12-21T23:00:05-05:00" />
<meta itemprop="dateModified" content="2020-12-21T23:00:05-05:00" />
<meta itemprop="wordCount" content="85">



<meta itemprop="keywords" content="" />
<meta property="og:title" content="第三章：PyTorch中的tensor相关操作总结" />
<meta property="og:description" content="PyTorch的核心数据类型tensor的相关操作" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yinjishen.github.io/pytorch/iii/" />
<meta property="article:published_time" content="2020-12-21T23:00:05-05:00" />
<meta property="article:modified_time" content="2020-12-21T23:00:05-05:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="第三章：PyTorch中的tensor相关操作总结"/>
<meta name="twitter:description" content="PyTorch的核心数据类型tensor的相关操作"/>
<link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" media="screen" href="https://yinjishen.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://yinjishen.github.io/css/main.css" />

        <link id="dark-scheme" rel="stylesheet" type="text/css" href="https://yinjishen.github.io/css/dark.css" />

	<script src="https://yinjishen.github.io/js/feather.min.js"></script>
	
		<script src="https://yinjishen.github.io/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	
	<h1 class="site-title"><a href="https://yinjishen.github.io/">Jishen Yin</a></h1>
	<div class="site-description"><nav class="nav social">
			<ul class="flat"><li><a href="https://github.com/YinJishen" title="Github"><i data-feather="github"></i></a></li></ul>
		</nav></div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/bio">Biostat 823</a>
			</li>
			
			<li>
				<a href="/pytorch">Pytorch</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post">
			<div class="post-header">
				
					<div class="meta">
						<div class="date">
							<span class="day">21</span>
							<span class="rest">Dec 2020</span>
						</div>
					</div>
				
				<div class="matter">
					<h1 class="title">第三章：PyTorch中的tensor相关操作总结</h1>
				</div>
			</div>
					
			<div class="markdown">
				<p>此为深度学习书籍《Deep Learning with Pytorch》学习笔记整理系列第三期，因为电脑配置问题，将跳过涉及CUDA/GPU的内容</p>
<p>书籍pdf链接：https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf</p>
<p>书籍附源代码链接：https://github.com/deep-learning-with-pytorch/dlwpt-code</p>
<p>注：所有实现代码均包含以下命令，此后将省略</p>
<pre><code>%matplotlib inline
import matplotlib.pyplot as plt #导入可视化库matplotlib.pyplot
import numpy as np #导入tensor常规处理库

#Pytorch主要部件导入
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

torch.set_printoptions(edgeitems=2) #输出长tensor时，保留首尾各2个元素
torch.manual_seed(123) #设置随机数种子
</code></pre><h1 id="第三章tensor">第三章：Tensor</h1>
<h2 id="31-浮点数的世界">3.1 浮点数的世界</h2>
<p>PyTorch处理数据的主要渠道是浮点数，无论是何种形式的数据（图片、文字、语音等等），都需要通过适当的模型转化成浮点数数据，才能有效地输入网络进行训练。</p>
<p><img src="/pytorch/3/3-1.PNG" alt="image"></p>
<!-- raw HTML omitted -->
<p>PyTorch引入了数据结构张量（tensor）来存储并处理浮点数数据。张量，通俗地讲，就是多维向量。多维向量的维度代表从整体索引到具体的标量元素所需要的下标数量。</p>
<p><img src="/pytorch/3/3-2.PNG" alt="image"></p>
<!-- raw HTML omitted -->
<h2 id="32-pytorch关于tensor的基本操作">3.2 PyTorch关于tensor的基本操作</h2>
<h3 id="构造">构造</h3>
<p>如何创建一个tensor？三种方式</p>
<ol>
<li>将其它形式的数据转化成<code>torch.Tensor</code>，例如<code>torch.from_numpy()</code>、<code>torch.tensot()</code>等</li>
<li>构造指定维度的零向量或一向量，例如<code>zeros</code>、<code>ones</code>等</li>
<li>生成随机向量，例如<code>randn</code>、<code>normal</code>等</li>
</ol>
<h3 id="索引切片变换等">索引、切片、变换等</h3>
<p>注：索引一律”左闭右开“，即包含起点，不包含终点</p>
<p>一维索引：</p>
<p><code>points[1:4]</code>指从1号元素到4号元素（不包含4号元素）</p>
<p><code>points[1:]</code>指从1号元素到末尾</p>
<p><code>points[:-1]</code>指从头到倒数第一位元素（不包含倒数第一位元素）</p>
<p>二维索引：</p>
<p><code>points[1:, :]</code>指从1号行到末尾，所有列的元素</p>
<p><code>points[1:, :]</code>指从1号行到末尾，0号列的元素</p>
<p>变形：</p>
<p><code>points.transpose()</code>：转置</p>
<p><code>points.t()</code>：无复制转置（变量存储地址不变）</p>
<h3 id="数学操作加下划线_可能变为内部操作即in-place">数学操作（加下划线_可能变为内部操作，即in-place）</h3>
<p>逐点运算：<code>cos</code>、<code>abs</code>等</p>
<p>降维运算：<code>mean</code>、<code>std</code>、<code>norm</code>等</p>
<p>比较运算：<code>equal</code>、<code>max</code>等</p>
<h3 id="其他操作">其他操作</h3>
<p>存取操作（<code>load</code>、<code>save</code>）及并行操作（<code>set_num_threads</code>）等</p>
<h2 id="33-pytorch关于tensor的进阶操作">3.3 PyTorch关于tensor的进阶操作</h2>
<h3 id="存储">存储</h3>
<p>使用<code>points.storage()</code>即可获取tensor的存储方式，无论是什么维度，都以一维方式进行存储，例如<code>torch.tensor([[2, 4], [1, 3]])</code>存储后即为<code>[2, 4, 1, 3]</code>。<code>storage</code>既可用于索引，也可用于修改</p>
<h3 id="尺寸偏移量步长">尺寸、偏移量、步长</h3>
<p>这三个变量与<code>storage</code>息息相关。尺寸（<code>size</code>）就是每个维度的长度构成的向量。偏移量（<code>offset</code>）是指某一切片到起点存储位置的距离。步长（<code>stride</code>）是指通过<code>storage</code>将tensor展成一维之后，所有维度向前前进一步，对应的一维向量需要向前走几步。</p>
<p>例如：一个尺寸为【3，4，5】的tensor，步长为【20，5，1】</p>
<h3 id="tensor里的数据类型">tensor里的数据类型</h3>
<p>常用的三种为<code>torch.float</code>（32位）、<code>torch.int</code>（32位）、torch.bool</p>

			</div>

			<div class="tags">
				
					
				
			</div></div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div>2020  <a href="https://github.com/knadh/hugo-ink">Ink</a> theme on <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>

<script>feather.replace()</script>
</body>
</html>
